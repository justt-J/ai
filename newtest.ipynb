{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de42f83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement yfiles_jupyter_graphspython-dotenv (from versions: none)\n",
      "ERROR: No matching distribution found for yfiles_jupyter_graphspython-dotenv\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-core langchain-community langchain-openai langchain-ollama langchain-experimental langchainhub neo4j tiktoken yfiles_jupyter_graphspython-dotenv json-repair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef4a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "\n",
    "# Strict atomic knowledge schema\n",
    "allowed_nodes = [\"Person\", \"Attribute\", \"Location\", \"Event\", \"Organization\", \"Object\", \"Legend\", \"Entity\"]\n",
    "allowed_relationships = [\n",
    "    (\"Person\", \"has_attribute\", \"Attribute\"),\n",
    "    (\"Person\", \"related_to\", \"Person\"),\n",
    "    (\"Person\", \"lives_in\", \"Location\"),\n",
    "    (\"Person\", \"works_at\", \"Organization\"),\n",
    "    (\"Person\", \"interacts_with\", \"Person\"),\n",
    "    (\"Person\", \"participated_in\", \"Event\"),\n",
    "    (\"Person\", \"discovered\", \"Object\"),\n",
    "    (\"Object\", \"linked_to\", \"Legend\"),\n",
    "    (\"Location\", \"contains\", \"Object\"),\n",
    "    (\"Legend\", \"mentions\", \"Entity\"),\n",
    "    (\"Entity\", \"is_part_of\", \"Event\"),\n",
    "    (\"Organization\", \"operates_in\", \"Location\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e68f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhay\\AppData\\Local\\Temp\\ipykernel_26688\\3956208501.py:30: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"deepseek-r1:8b\", temperature=0),\n",
      "C:\\Users\\jhay\\AppData\\Local\\Temp\\ipykernel_26688\\3956208501.py:29: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Extract a structured knowledge graph from this narrative. \n",
    "Use ONLY these node types: Person, Attribute, Location, Event, Organization, Object, Legend, Entity.\n",
    "Use ONLY these relationships:\n",
    "- Person → has_attribute → Attribute\n",
    "- Person → related_to → Person\n",
    "- Person → lives_in → Location\n",
    "- Person → works_at → Organization\n",
    "- Person → interacts_with → Person\n",
    "- Person → participated_in → Event\n",
    "- Person → discovered → Object\n",
    "- Object → linked_to → Legend\n",
    "- Location → contains → Object\n",
    "- Legend → mentions → Entity\n",
    "- Entity → is_part_of → Event\n",
    "- Organization → operates_in → Location\n",
    "\n",
    "Rules:\n",
    "- Each node must contain only one atomic fact.\n",
    "- Do NOT include full paragraphs or sentences in nodes.\n",
    "- Prefer people, their roles, traits, and what they interact with.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Return JSON with \"nodes\" and \"edges\".\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "chain = LLMChain(\n",
    "    llm = Ollama(model=\"deepseek-r1:8b\", temperature=0),\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81620802",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"deepseek-r1:8b\", temperature=0)\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=allowed_nodes,\n",
    "    allowed_relationships=allowed_relationships,\n",
    "    strict_mode=True,\n",
    "    node_properties=False,\n",
    "    relationship_properties=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbaff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(\"dum.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split by paragraph for finer processing\n",
    "paragraphs = [Document(page_content=p.strip()) for p in text.split(\"\\n\\n\") if p.strip()]\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd81be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"your_password\",\n",
    "    refresh_schema=False\n",
    ")\n",
    "\n",
    "for doc in graph_documents:\n",
    "    graph.add_graph_document(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce76ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "qa_chain = GraphCypherQAChain.from_llm(\n",
    "    cypher_llm=ChatOpenAI(temperature=0),\n",
    "    qa_llm=ChatOpenAI(temperature=0),\n",
    "    graph=graph,\n",
    "    validate_cypher=True,\n",
    "    use_function_response=True\n",
    ")\n",
    "\n",
    "# Example question:\n",
    "result = qa_chain.run(\"What did Eleanor discover in the library?\")\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
